import pandas as pd
import streamlit as st
import logging
import json
import urllib.parse
from datetime import datetime, timedelta

from trendspy.client import Trends

# --- ê¸°ë³¸ ì„¤ì • ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
st.set_page_config(page_title="ëŒ€ì„  í…Œë§ˆì£¼ ê²€ìƒ‰ëŸ‰ ì‹œê°í™”", page_icon="ğŸ“ˆ", layout="wide")

@st.cache_resource
def get_trends_client():
    """Trendspy í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³  ìºì‹±í•©ë‹ˆë‹¤."""
    logging.info("Trends í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
    return Trends(retries=3, backoff_factor=0.5, timeout=(10, 25))

# --- ì„¤ì •ê°’ ---
MONITORING_KEYWORDS = ["ë•ì„±", "ìƒì§€ê±´ì„¤", "ì•ˆë©", "ì¨ë‹ˆì „ì", "í‰í™”ì‚°ì—…", "ì½”ë‚˜ì•„ì´"]

INDIVIDUAL_ANALYSIS_LIST = {
    "ë•ì„±":     {"start_date": "2021-09-18", "end_date": "2022-03-16", "label": "20ëŒ€ ê¸°ê°„"},
    "ì•ˆë©":     {"start_date": "2021-09-18", "end_date": "2022-03-16", "label": "20ëŒ€ ê¸°ê°„"},
    "ì¨ë‹ˆì „ì": {"start_date": "2021-09-18", "end_date": "2022-03-16", "label": "20ëŒ€ ê¸°ê°„"},
    "ìƒì§€ê±´ì„¤": {"start_date": "2024-12-14", "end_date": "2025-06-10", "label": "21ëŒ€ ê¸°ê°„"},
    "í‰í™”ì‚°ì—…": {"start_date": "2024-12-14", "end_date": "2025-06-10", "label": "21ëŒ€ ê¸°ê°„"},
    "ì½”ë‚˜ì•„ì´": {"start_date": "2024-12-14", "end_date": "2025-06-10", "label": "21ëŒ€ ê¸°ê°„"}
}
# --- ë°±ì—”ë“œ í•¨ìˆ˜ ---
@st.cache_data(ttl=3600)
def fetch_daily_interest(_tr_obj, keywords, days=240, geo="KR"):
    if not keywords: return pd.DataFrame()
    end_date = pd.Timestamp.now()
    start_date = end_date - pd.DateOffset(days=days - 1)
    timeframe = f"{start_date.strftime('%Y-%m-%d')} {end_date.strftime('%Y-%m-%d')}"
    try:
        df = _tr_obj.interest_over_time(keywords, timeframe=timeframe, geo=geo)
        if 'ì¼' in df.columns: df = df.set_index('ì¼')
        elif 'Day' in df.columns: df = df.set_index('Day')
        df.index = pd.to_datetime(df.index)
        if 'isPartial' in df.columns: df = df.drop(columns=['isPartial'])
        if len(df.columns) == len(keywords): df.columns = keywords
        else: df = df.rename(columns={col: col.split(':')[0] for col in df.columns})
        for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')
        df = df.fillna(0).astype(int)
        return df.sort_index()
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

def format_trend_data(series: pd.Series) -> pd.DataFrame:
    series = series.sort_index(ascending=True)
    processed_records = []
    in_zero_streak, streak_start_date = False, None
    sentinel_date = series.index.max() + pd.DateOffset(days=1)
    series_with_sentinel = pd.concat([series, pd.Series([1], index=[sentinel_date])])
    for date, value in series_with_sentinel.items():
        if value == 0:
            if not in_zero_streak: in_zero_streak, streak_start_date = True, date
        else:
            if in_zero_streak:
                streak_end_date = date - pd.DateOffset(days=1)
                period_str = f"{streak_start_date.strftime('%Y-%m-%d')} ~ {streak_end_date.strftime('%Y-%m-%d')}" if streak_start_date != streak_end_date else streak_start_date.strftime('%Y-%m-%d')
                processed_records.append({'sort_key': streak_start_date, 'ê¸°ê°„': period_str, 'ê²€ìƒ‰ëŸ‰': 0})
                in_zero_streak = False
            if date != sentinel_date:
                processed_records.append({'sort_key': date, 'ê¸°ê°„': date.strftime('%Y-%m-%d'), 'ê²€ìƒ‰ëŸ‰': int(value)})
    if not processed_records: return pd.DataFrame(columns=['ê¸°ê°„', 'ê²€ìƒ‰ëŸ‰'])
    result_df = pd.DataFrame(processed_records).sort_values(by='sort_key', ascending=False)
    return result_df.drop(columns=['sort_key']).reset_index(drop=True)

def generate_trends_embed_html(keywords: list, start_date_str: str, end_date_str: str) -> str:
    time_str = f"{start_date_str} {end_date_str}"
    comparison_list = [{"keyword": kw, "geo": "KR", "time": time_str} for kw in keywords]
    comparison_item_json = json.dumps(comparison_list)
    q_param = urllib.parse.quote(','.join(keywords))
    explore_query_str = f"date={urllib.parse.quote(time_str)}&geo=KR&q={q_param}&hl=ko"
    return f"""
        <script type="text/javascript" src="https://ssl.gstatic.com/trends_nrtr/4116_RC01/embed_loader.js"></script>
        <script type="text/javascript">
        trends.embed.renderExploreWidget("TIMESERIES", {{"comparisonItem":{comparison_item_json},"category":0,"property":""}}, {{"exploreQuery":"{explore_query_str}","guestPath":"https://trends.google.com:443/trends/embed/"}});
        </script>"""

# --- Streamlit UI êµ¬ì„± ---
tr = get_trends_client()

with st.sidebar:
    st.title("ë©”ë‰´")
    page_choice = st.radio("í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”.", ("ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„", "ì§€ì • ê¸°ê°„ íŠ¸ë Œë“œ ë¶„ì„"))

if page_choice == "ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„":
    st.header("ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„ (ìµœê·¼ 240ì¼)")
    with st.sidebar:
        st.divider()
        st.header("âš™ï¸ ì‹¤ì‹œê°„ ë¶„ì„ ì˜µì…˜")
        selected_keywords = st.multiselect(
            "ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (ìµœëŒ€ 5ê°œ):",
            options=MONITORING_KEYWORDS,
            default=["ì½”ë‚˜ì•„ì´"],
            max_selections=5
        )
        if st.button("ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
            st.cache_data.clear()
            st.rerun()

    if not selected_keywords:
        st.warning("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        end_date_realtime = datetime.now()
        start_date_realtime = end_date_realtime - timedelta(days=239)
        html_code = generate_trends_embed_html(selected_keywords, start_date_realtime.strftime('%Y-%m-%d'), end_date_realtime.strftime('%Y-%m-%d'))
        st.components.v1.html(html_code, height=500)
        df_trends = fetch_daily_interest(tr, selected_keywords, days=240)
        if not df_trends.empty:
            with st.expander("ìì„¸í•œ ë°ì´í„° ë³´ê¸° (0ì¸ ê¸°ê°„ ìš”ì•½)"):
                tabs = st.tabs([f"'{kw}'" for kw in selected_keywords])
                for i, keyword in enumerate(selected_keywords):
                    with tabs[i]:
                        display_df = format_trend_data(df_trends[keyword])
                        st.dataframe(display_df, use_container_width=True, hide_index=True)

elif page_choice == "ì§€ì • ê¸°ê°„ íŠ¸ë Œë“œ ë¶„ì„":
    st.header("ì§€ì • ê¸°ê°„ íŠ¸ë Œë“œ ë¶„ì„")
    
    # --- â˜… íƒ­ ìƒì„± ---
    tab20, tab21 = st.tabs(["20ëŒ€ ê¸°ê°„", "21ëŒ€ ê¸°ê°„"])

    with tab20:
        # 20ëŒ€ ê¸°ê°„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ê¸°ì¤€)
        period_data = INDIVIDUAL_ANALYSIS_LIST["ë•ì„±"]
        st.info(f"**ë¶„ì„ ê¸°ê°„:** {period_data['start_date']} ~ {period_data['end_date']}")
        st.divider()

        # '20ëŒ€ ê¸°ê°„'ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
        for keyword, data in INDIVIDUAL_ANALYSIS_LIST.items():
            if data['label'] == '20ëŒ€ ê¸°ê°„':
                st.subheader(f"ğŸ“Š '{keyword}' íŠ¸ë Œë“œ")
                period_html_code = generate_trends_embed_html([keyword], data["start_date"], data["end_date"])
                st.components.v1.html(period_html_code, height=500)

    with tab21:
        # 21ëŒ€ ê¸°ê°„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ê¸°ì¤€)
        period_data = INDIVIDUAL_ANALYSIS_LIST["ìƒì§€ê±´ì„¤"]
        st.info(f"**ë¶„ì„ ê¸°ê°„:** {period_data['start_date']} ~ {period_data['end_date']}")
        st.divider()

        # '21ëŒ€ ê¸°ê°„'ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
        for keyword, data in INDIVIDUAL_ANALYSIS_LIST.items():
            if data['label'] == '21ëŒ€ ê¸°ê°„':
                st.subheader(f"ğŸ“Š '{keyword}' íŠ¸ë Œë“œ")
                period_html_code = generate_trends_embed_html([keyword], data["start_date"], data["end_date"])
                st.components.v1.html(period_html_code, height=500)