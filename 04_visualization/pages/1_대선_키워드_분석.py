import streamlit as st
import pandas as pd
from datetime import datetime
import os
import pathlib
from utils.chart import ChartGenerator

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€

APP_DIR = pathlib.Path(__file__).parent.parent.resolve()  # app.py ê¸°ì¤€ ë””ë ‰í† ë¦¬

ROUND_OPTIONS = {
    "ì œ20ëŒ€": {
        "keyword_path": os.path.join(APP_DIR, "data/ì œ20ëŒ€_ëŒ€ì„ í›„ë³´_ì¢…ëª©ë³„_í‚¤ì›Œë“œ.csv"),
        "price_dir": os.path.join(APP_DIR, "price_data/ì œ20ëŒ€_ëŒ€ì„ _í…Œë§ˆì£¼/"),
        "article_path": os.path.join(APP_DIR, "data/ì œ20ëŒ€_ì „ì²´_í†µí•©_ê¸°ì‚¬.csv"),
        "paxnet_path": os.path.join(APP_DIR, "../01_ë°ì´í„°ìˆ˜ì§‘/ë¹„ì •í˜•ë°ì´í„°/faxnet_20/íŒìŠ¤ë„·_20ëŒ€_ëŒ€ì„ _í…Œë§ˆì£¼_í¬ë¡¤ë§_20250627.csv"),
        "naver_path": os.path.join(APP_DIR, "../01_ë°ì´í„°ìˆ˜ì§‘/ë¹„ì •í˜•ë°ì´í„°/stock_community/output/csv/ì œ20ëŒ€_ëŒ€ì„ _í…Œë§ˆì£¼/"),
        "start_date": datetime(2022, 2, 5),
        "end_date": datetime(2022, 3, 16)
    },
    "ì œ21ëŒ€": {
        "keyword_path": os.path.join(APP_DIR, "data/ì œ21ëŒ€_ëŒ€ì„ í›„ë³´_ì¢…ëª©ë³„_í‚¤ì›Œë“œ.csv"),
        "price_dir": os.path.join(APP_DIR, "price_data/ì œ21ëŒ€_ëŒ€ì„ _í…Œë§ˆì£¼/"),
        "article_path": os.path.join(APP_DIR, "data/ì œ21ëŒ€_ì „ì²´_í†µí•©_ê¸°ì‚¬.csv"),
        "paxnet_path": os.path.join(APP_DIR, "../01_ë°ì´í„°ìˆ˜ì§‘/ë¹„ì •í˜•ë°ì´í„°/faxnet_21/íŒìŠ¤ë„·_21ëŒ€_ëŒ€ì„ _í…Œë§ˆì£¼_í¬ë¡¤ë§_20250627.csv"),
        "naver_path": os.path.join(APP_DIR, "../01_ë°ì´í„°ìˆ˜ì§‘/ë¹„ì •í˜•ë°ì´í„°/stock_community/output/csv/ì œ21ëŒ€_ëŒ€ì„ _í…Œë§ˆì£¼/"),
        "start_date": datetime(2025, 5, 3),
        "end_date": datetime(2025, 6, 10)
    },
}

st.title("ğŸ“Š ëŒ€ì„  í…Œë§ˆì£¼ í‚¤ì›Œë“œ ë¶„ì„")

selected_round = st.selectbox("ëŒ€ì„  íšŒì°¨ ì„ íƒ", list(ROUND_OPTIONS.keys()))
config = ROUND_OPTIONS[selected_round]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_keyword_df(path):
    df = pd.read_csv(path)
    df["í‚¤ì›Œë“œ"] = df["í‚¤ì›Œë“œ"].apply(eval)
    return df

@st.cache_data
def load_or_generate_article_df(article_path, paxnet_path, naver_path):
    if os.path.exists(article_path):
        return pd.read_csv(article_path, parse_dates=["ë‚ ì§œ"])

    # â”€â”€ íŒìŠ¤ë„· ë¡œë”© â”€â”€
    paxnet_df = pd.read_csv(paxnet_path)
    paxnet_df["ë‚ ì§œ"] = pd.to_datetime(paxnet_df["ë‚ ì§œ"])
    paxnet_df = paxnet_df[["ì¢…ëª©ëª…", "ë‚ ì§œ", "ì œëª©", "ë‚´ìš©"]]

    # â”€â”€ ë„¤ì´ë²„ ì¢…í† ë°© ë¡œë”© â”€â”€
    csv_files = [f for f in os.listdir(naver_path) if f.endswith(".csv")]
    dataframes = []
    for file in csv_files:
        try:
            df = pd.read_csv(os.path.join(naver_path, file))
            df['filename'] = file
            dataframes.append(df)
        except Exception as e:
            print(f"íŒŒì¼ ì˜¤ë¥˜: {file} - {e}")
    naver_df = pd.concat(dataframes, ignore_index=True)
    naver_df["ë‚ ì§œ"] = pd.to_datetime(naver_df["article_date"])
    naver_df.rename(columns={
        "stock_name": "ì¢…ëª©ëª…",
        "article_title": "ì œëª©",
        "article_content": "ë‚´ìš©"
    }, inplace=True)
    naver_df = naver_df[["ì¢…ëª©ëª…", "ë‚ ì§œ", "ì œëª©", "ë‚´ìš©"]]

    # â”€â”€ ë³‘í•© ë° ì €ì¥ â”€â”€
    all_df = pd.concat([paxnet_df, naver_df], ignore_index=True)
    all_df.to_csv(article_path, index=False)
    return all_df

keyword_df = load_keyword_df(config["keyword_path"])
article_df = load_or_generate_article_df(config["article_path"], config["paxnet_path"], config["naver_path"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ í›„ë³´ / ì¢…ëª© ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€
candidates = keyword_df["í›„ë³´"].unique().tolist()
selected_candidate = st.radio("í›„ë³´ ì„ íƒ", candidates)

filtered_df = keyword_df[keyword_df["í›„ë³´"] == selected_candidate]
stock = st.selectbox("ì¢…ëª© ì„ íƒ", sorted(filtered_df["ì¢…ëª©ëª…"].unique()))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‚¤ì›Œë“œ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€
stock_keywords = filtered_df[filtered_df["ì¢…ëª©ëª…"] == stock]["í‚¤ì›Œë“œ"].values[0]
sorted_keywords = sorted(stock_keywords.items(), key=lambda x: x[1], reverse=True)

st.subheader(f"ğŸ“Œ {stock} í‚¤ì›Œë“œ (ë¹ˆë„ ê¸°ì¤€)")

# ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ
top_n = 10
top_df = pd.DataFrame(sorted_keywords[:top_n], columns=["í‚¤ì›Œë“œ", "ë¹ˆë„ìˆ˜"])
st.table(top_df)

# ì „ì²´ í‚¤ì›Œë“œëŠ” í¼ì¹˜ê¸°(expander)ë¡œ ê°ì¶”ê¸°
with st.expander("ğŸ“‚ ì „ì²´ í‚¤ì›Œë“œ ë”ë³´ê¸°"):
    full_df = pd.DataFrame(sorted_keywords, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„ìˆ˜"])
    st.dataframe(full_df, use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€
generator = ChartGenerator(keyword_df=keyword_df, article_df=article_df, price_dir=config["price_dir"])

st.subheader("â˜ï¸ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
try:
    fig_wc = generator.plot_wordcloud(stock)
    st.pyplot(fig_wc)
except Exception as e:
    st.warning(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë²„ì¦ˆ ì°¨íŠ¸ ì‹œê°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    buzz_df = generator.extract_keywords_by_date(stock, start_date=config["start_date"], end_date=config["end_date"])
    merged_df = generator.merge_with_price(stock, buzz_df, start_date=config["start_date"], end_date=config["end_date"])

    st.subheader("ğŸ“ˆ ì£¼ê°€ vs í‚¤ì›Œë“œ ì–¸ê¸‰ëŸ‰")
    fig = generator.plot_buzz_chart(merged_df, stock)
    st.pyplot(fig)
except Exception as e:
    st.warning(f"ì‹œê°í™” ì‹¤íŒ¨: {e}")