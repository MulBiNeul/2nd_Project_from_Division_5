# 코드 명세서: `naver_stock_community_crwaler_v.0.9.py`

#### 1. 개요

본 파이썬 스크립트는 **네이버 증권 토론방** 의 게시글을 병렬로 크롤링하기 위해 설계되었습니다. 사용자는 CSV 파일에 정의된 종목 목록과 날짜 범위를 기반으로 특정 기간의 게시글 제목, 내용, 댓글, 조회수 등 상세 정보를 수집하여 CSV 파일로 저장할 수 있습니다.

#### 2. 주요 기능

* **종목 목록 기반 크롤링** : `stock_list.csv` 파일에 정의된 종목 리스트를 읽어와 크롤링을 수행합니다.
* **날짜 범위 지정** : 각 종목별로 크롤링할 시작일(`start_date`)과 종료일(`end_date`)을 지정할 수 있습니다.
* **효율적인 페이지 탐색** : 크롤링 시작 전, 목표 날짜(`end_date`)가 포함된 게시판 페이지를 **추론 및 이진 탐색과 유사한 방식으로 탐색** 하여 불필요한 페이지 순회를 최소화합니다.
* **병렬 처리** : 파이썬의 `ThreadPoolExecutor`를 사용하여 여러 종목을 동시에 크롤링하므로 작업 시간을 크게 단축합니다.
* **상세 정보 수집** : 각 게시글의 제목, 본문, 작성자, 작성일, 조회수, 좋아요/싫어요 수, 댓글 전체를 수집합니다.
* **커맨드 라인 인터페이스** : `argparse`를 활용하여 파일 경로, 병렬 작업자 수, 필터링 옵션을 유연하게 설정할 수 있습니다.
* **봇 탐지 회피** : `headless` 브라우저 옵션과 랜덤한 딜레이(`apply_random_delay`)를 적용하여 웹사이트의 봇 탐지를 우회하려는 시도가 포함되어 있습니다.

#### 3. 실행 방법

터미널(커맨드 프롬프트)에서 아래와 같이 실행합니다.

**Bash**

```
python naver_stock_community_crwaler_v.0.9.py [OPTIONS]
```

* **Options** :
  * `-f` 또는 `--file`: 크롤링할 종목 목록이 담긴 CSV 파일 경로 (기본값: `data/stock_list.csv`)
  * `-w` 또는 `--workers`: 동시에 실행할 스레드(작업자) 수 (기본값: 3)
  * `-o` 또는 `--option`: 필터링할 키워드 (예: "20대 이재명"). 이 키워드를 포함하는 종목만 크롤링합니다.
  * `-l` 또는 `--logic` : 필터링 할 키워드 간에 논리 연산을 설정합니다. or, and 중에 선택 (기본값 or)

#### 4. 프로세스 흐름

1. **초기화** : 사용자가 입력한 인자(파일 경로, 작업자 수, 키워드 등)를 파싱합니다.
2. **종목 목록 로드** : `load_theme_stock_list` 함수가 CSV 파일을 `pandas` DataFrame으로 로드하고, 사용자가 필터링 옵션을 제공했다면 `filter_stock_list` 함수를 통해 크롤링 대상을 선별합니다.
3. **병렬 작업 설정** : `ThreadPoolExecutor`를 생성하고, 각 종목에 대한 크롤링 작업을 작업 큐에 추가합니다.
4. **개별 종목 크롤링 (`scrape_stock_articles_by_date_range` 함수)** :
   a. **드라이버 초기화** : 각 스레드는 독립적인 `Selenium` 웹 드라이버를 생성합니다.
   b. **날짜 범위 확인** : 게시판의 첫 페이지와 마지막 페이지를 방문하여 전체 게시글의 날짜 범위를 확인하고, 사용자가 지정한 날짜 범위가 유효한지 검사합니다.
   c. **시작 페이지 탐색** :
   i.  전체 페이지 수와 날짜 범위를 기반으로 목표 종료일(`end_date`)이 있을 법한 페이지를 **수학적으로 추론** 합니다.
   ii. 추론된 페이지에서 다시 날짜를 확인하고, 목표 날짜와의 거리에 따라 가중치를 적용하여 다음 탐색할 페이지로 이동하는 과정을 반복합니다.
   iii. 목표 날짜에 충분히 근접하면, 페이지를 하나씩 이동하는 **정밀 탐색** 으로 전환하여 `end_date`가 포함된 정확한 페이지를 찾습니다.
   d. **게시글 수집** :
   i.  찾아낸 시작 페이지부터 1페이지 방향(시간상 과거 -> 최신)으로 이동하며 크롤링을 진행합니다.
   ii.  페이지 내의 모든 게시글 목록을 가져와, 각 게시글의 날짜를 확인합니다.
   iii. 게시글 날짜가 지정된 범위(`start_date` ~ `end_date`)에 해당하면, 해당 게시글의 상세 페이지로 이동하여 **본문과 댓글 등 상세 정보를 수집** 합니다.
   iv. 수집된 데이터는 리스트에 추가하고, 상세 페이지 크롤링 후에는 다시 게시판 목록 페이지로 돌아옵니다.
   v.  게시글 날짜가 `start_date`보다 과거이면 해당 종목의 크롤링을 종료합니다.
   e. **데이터 저장** : 한 페이지의 크롤링이 끝날 때마다, 그리고 해당 종목의 모든 크롤링이 완료되었을 때 `save_to_csv` 함수를 호출하여 중간 결과를 파일에 저장합니다.
5. **종료** : 모든 종목에 대한 크롤링이 완료되면, 프로그램을 종료합니다.
